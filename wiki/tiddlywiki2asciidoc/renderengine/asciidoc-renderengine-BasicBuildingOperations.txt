== BasicBuildingOperations
:Author: Ichthyostega
:Date Created: 200712040334
:Date Changed: 200805210230
:Count Changes: 24
// design dynamic Builder img

Starting out from the concepts of Objects, Placement to Tracks, render Pipes and connection properties ( -> see <<renderengine-TrackPipeEDL,here>>) within the EDL, we can identify the elementary operations occuring within the Builder. Overall, the Builder is organized as application of _visiting tools_ to a collection of objects, so finally we have to consider some object kind appearing in the working function of the given builder tool, which holds at this moment some _context_. The job now is to organize this context such as to create a predictable build process from this _event driven_ approach.
 ->see also: BuilderPrimitives for the elementary situations used to cary out the building operations

=== Builder working Situations
. any *Clip* (which at this point has been reduced already to a part of a simple elementary media stream  -> see <<renderengine-Fixture,Fixture>>)
.. yields a source reading node
.. which needs to be augmented by the underlying media's <<renderengine-ProcPatt,processing pattern>>
+
--
* thus inserting codec(s) and source transformations
* effectively this is an application of effects
--
.. at this point we have to process (and maybe generate on-the-fly) the <<renderengine-ClipSourcePort,source port of this clip>>
+
--
* the output of the source reading and preprocessing defined thus far is delivered as input to this port, which is done by a WiringRequest (see below)
* as every port, it is the entry point to a <<renderengine-Pipe,processing pipe>>, thus the source port has a processing pattern, typically inserting the camera (transformation effect) at this point
--
.. followed by the application of effects
+
--
* separately for every effect chain rooted (placed) directly onto the clip
* and regarding the chaining order
--
.. next we have to assess the <<renderengine-Pipe,pipes>> to which the clip has been placed
.. producing a <<renderengine-WiringRequest,wiring request>> for every pair +(chainEndpoint, pipe)+
+
image::../draw/Proc.builder1.png[]
. attaching an *Effect* is actually always an _insertion operation_ which is done by _prepending_ to the previously built nodes. Effects may be placed as attached to clips and pipes, which causes them to be included in the processing chain at the given location. Effects may as well be placed at an absolute time, which means they are to be applied to every clip that happens to be at this time -- but this usecase will be reolved when creating the Fixture, causing the effect to be attached to the clips in question. The same holds true for Effects put on tracks.
. treating an *wiring request* means
.. detecting possible and impossible connections
.. deriving additional possible 'placement dimensions' generated by executing such an connection (e.g. connecting a mono source to a spatial sound system bus creates panning possibilities)
+
--
* deriving parameter sources for this additional degrees of freedom
* fire off insertion of the necessary effects to satisfy this connection request and implement the additional 'placement dimensions' (pan, layer order, overlay mode, MIDI channel selection...)
--
. processing the effects and further placements *attached to a Pipe* is handled identical to the processing done with all attachments to individual clips.
. *Transitions* are to be handled differently according to their placement ( -> more on <<renderengine-TransitionsHandling,Transitions>>)
 * when placed normally to two (or N) clips, they are inserted at the exit node of the clip's complete effect chain.
 * otherwise, when placed to the source port(s) or when placed to some other pipes they are inserted at the exit side of those pipe's effect chains. (Note: this puts additional requirements on the transition processor, so not every transition can be placed this way)
After consuming all input objects and satisfying all wiring requests, the result is a set of <<renderengine-ExitNode,exit nodes>> ready for pulling data. We call the network reachable from such an exit node a <<renderengine-Processor,Processor>>, together all processors of all segments and output data types comprise the render engine.

==== dependencies
Pipes need to be there first, as everything else will be plugged (placed) to a pipe at some point. The same holds true for tracks. But, on the other hand, both are optional. We can have EDLs with MObjects without configuring pipes (but won't be able to build any render processor of course). And we could have an EDL without any track, if we place every MObject within this EDL directly to some pipe.

Effects can be attached only to already existing pipelines, starting out at some pipes entry port or the source port of some clip. Besides that, all further parts can be built in any order and independent of each other. This is made possible by using <<renderengine-WiringRequest,wiring requests>>, which can be resolved later on. So, as long as we start out with the tracks (to resolve any pipe they are placed to), and further, if we manage to get any effect placed to some clip-MO _after_ setting up and treating the clip, we are fine and can do the building quasi event driven.

==== building and resolving
Building the network for the individual objects thus creates a queue of wiring requests. Some of them may be immediately resolvable, but detecting this correctly can be nontrivial, and so it seems better to group all wiring requests based on the pipe and treat them groupwise. Because -- in the most general case -- connecting includes the use of transforming and joining nodes, which can create additional wiring requests (e.g. for automation parameter data connections). Finally, if the network is complete, we could perform <<renderengine-RenderNetworkOptimisation,optimisations>>